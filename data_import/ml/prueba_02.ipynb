{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71c3381",
   "metadata": {},
   "source": [
    "### OJO üëÅÔ∏èüëÅÔ∏è\n",
    "con la base de CHATGPT >>\n",
    " comparar metodolog√≠a con el curso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca5dc2",
   "metadata": {},
   "source": [
    "Dejo un requirements.txt para que corra este pipeline en: <code>/entorno_conda/tfm-ml/requirements.txt</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, explained_variance_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skops.io import dump, load, get_untrusted_types\n",
    "from zipfile import ZIP_DEFLATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Carga de datos\n",
    "completo = pd.read_csv('transform_listings.csv')\n",
    "df = completo[['neighbourhood_group_cleansed','bedrooms', 'bathrooms', 'price','latitude','longitude']]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 No hago preprocesado porque ya lo hice en el notebook de transform_listings\n",
    "\n",
    "# m√°s adelante filtro precios outliers para mejorar los resultados de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ceb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramay bigotes sin quitar outliers\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
    "df['price'].plot(kind='hist', ax=axes[0], bins=1000)\n",
    "# df['price'].plot(kind='hist', ax=axes[0], bins=int(np.sqrt(len(df['price']))))\n",
    "axes[0].set_title('Histograma de Precios')\n",
    "axes[0].set_xlabel('Precio')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "df['price'].plot(kind='box', ax=axes[1], vert=False)\n",
    "axes[1].set_title('Gr√°fico de Bigotes de Precios')\n",
    "axes[1].set_xlabel('Precio')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Filtro los outliers utilizando el rango intercuart√≠lico (IQR): \n",
    "# # # ¬øMejorar√≠a algo con z-score?\n",
    "Q1  = df['price'].quantile(0.25)\n",
    "Q3  = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "IQR\n",
    "df = df[(df['price']>=Q1 - 1.5 * IQR) & (df['price']<=Q3 + 1.5 * IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44365548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma y bigotes con outliers quitados (m√©todo IQR)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
    "df['price'].plot(kind='hist', ax=axes[0], bins=int(np.sqrt(len(df['price']))))\n",
    "axes[0].set_title('Histograma de Precios')\n",
    "axes[0].set_xlabel('Precio')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "df['price'].plot(kind='box', ax=axes[1], vert=False)\n",
    "axes[1].set_title('Gr√°fico de Bigotes de Precios')\n",
    "axes[1].set_xlabel('Precio')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# densifier = FunctionTransformer(lambda X: X.toarray() if hasattr(X, \"toarray\") else X)\n",
    "\n",
    "# 1. Carga y limpieza\n",
    "df = df.dropna(subset=['bedrooms','bathrooms','neighbourhood_group_cleansed','price'])\n",
    "\n",
    "# 2. Separar X/y\n",
    "X = df[['bedrooms','bathrooms','neighbourhood_group_cleansed']]\n",
    "y = df['price']\n",
    "\n",
    "# 3. Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Preprocesador: escala num√©ricos + one-hot para distrito\n",
    "numeric_feats = ['bedrooms','bathrooms']\n",
    "cat_feats     = ['neighbourhood_group_cleansed']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num',   StandardScaler(),    numeric_feats),\n",
    "    ('cat',   OneHotEncoder(drop='first', handle_unknown=\"ignore\", sparse_output=False), cat_feats),\n",
    "])\n",
    "\n",
    "# 5. Definir pipelines para cada modelo\n",
    "models = {\n",
    "    'LinearRegression': Pipeline([('prep', preprocessor),\n",
    "                                  ('reg',  LinearRegression())]),\n",
    "    'Ridge':            Pipeline([('prep', preprocessor),\n",
    "                                  ('reg',  Ridge(alpha=1.0, random_state=42))]),\n",
    "    'Lasso':            Pipeline([('prep', preprocessor),\n",
    "                                  ('reg',  Lasso(alpha=0.1, random_state=42))]),\n",
    "    'ElasticNet':       Pipeline([('prep', preprocessor),\n",
    "                                  ('reg',  ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42))]),\n",
    "    'KNeighbors':       Pipeline([('prep', preprocessor),\n",
    "                                  ('reg',  KNeighborsRegressor(n_neighbors=5))]),\n",
    "    'SVR':              Pipeline([('prep', preprocessor),\n",
    "                                  ('reg',  SVR(kernel='rbf', C=1.0))]),\n",
    "    'RandomForest':     Pipeline([('prep', preprocessor),\n",
    "                                  ('reg',  RandomForestRegressor(n_estimators=100, random_state=42))]),\n",
    "    'GradientBoosting': Pipeline([('prep', preprocessor),\n",
    "                                  ('reg',  GradientBoostingRegressor(\n",
    "                                      n_estimators=100, learning_rate=0.1, \n",
    "                                      max_depth=3, random_state=42))]),\n",
    "    'ExtraTrees': Pipeline([('prep', preprocessor),\n",
    "                            ('reg', ExtraTreesRegressor(n_estimators=100, random_state=42))]),\n",
    "    'AdaBoost': Pipeline([('prep', preprocessor),\n",
    "                          ('reg', AdaBoostRegressor(n_estimators=100, random_state=42))]),\n",
    "    'HistGradientBoosting': Pipeline([('prep', preprocessor),\n",
    "                                    #   ('densify',densifier),\n",
    "                                      ('reg', HistGradientBoostingRegressor(max_iter=100, random_state=42))]),\n",
    "    'MLPRegressor': Pipeline([('prep', preprocessor),\n",
    "                              ('reg', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, random_state=42))]),\n",
    "}\n",
    "\n",
    "# 6. Definir m√©tricas para cross_validate\n",
    "scoring = {\n",
    "    'MAE':   'neg_mean_absolute_error',\n",
    "    'RMSE':  'neg_root_mean_squared_error',\n",
    "    'R2':    'r2',\n",
    "    'MAPE':  'neg_mean_absolute_percentage_error',\n",
    "    'EVS':   'explained_variance',\n",
    "}\n",
    "\n",
    "# 7. Ejecutar validaci√≥n cruzada en train\n",
    "results = {}\n",
    "for name, pipe in models.items():\n",
    "    cv = cross_validate(pipe, X_train, y_train,\n",
    "                        cv=5, scoring=scoring,\n",
    "                        return_train_score=False)\n",
    "    # invertir signos de las m√©tricas negativas\n",
    "    mae_mean  = -cv['test_MAE'].mean()\n",
    "    rmse_mean = -cv['test_RMSE'].mean()\n",
    "    mape_mean = -cv['test_MAPE'].mean()\n",
    "    results[name] = {\n",
    "        'MAE':  mae_mean,\n",
    "        'RMSE': rmse_mean,\n",
    "        'R2':   cv['test_R2'].mean(),\n",
    "        'MAPE': mape_mean,\n",
    "        'EVS':  cv['test_EVS'].mean(),\n",
    "    }\n",
    "\n",
    "# 8. Mostrar comparativa ordenada por MAE\n",
    "results_df = pd.DataFrame(results).T.sort_values('MAE')\n",
    "display(results_df.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32fe8f",
   "metadata": {},
   "source": [
    "He visto esto respecto a m√©tricas:\n",
    "https://medium.com/@nicolasarrioja/m%C3%A9tricas-en-regresi%C3%B3n-5e5d4259430b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75773fe6",
   "metadata": {},
   "source": [
    "Exportamos el modelo para utilizarlo despu√©s en otros DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ddc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Tenemos results_df ya ordenado por MAE ascendente\n",
    "best_name, best_pipe = results_df.index[0], models[results_df.index[0]]\n",
    "\n",
    "# 1. Reentrenar con TODO el dataset de entrenamiento+validaci√≥n\n",
    "X_dev = pd.concat([X_train, X_test], axis=0)\n",
    "y_dev = pd.concat([y_train, y_test], axis=0)\n",
    "best_pipe.fit(X_dev, y_dev)\n",
    "\n",
    "# 2. Persistir de forma segura\n",
    "# dump(best_pipe, f\"{best_name}.skops\", compression=\"lzma\") ## Esta compresi√≥n me da problemas, creo que debo instalar algo en el entorno.\n",
    "dump(best_pipe, f\"pers_models/{best_name}.skops\", compression=ZIP_DEFLATED, compresslevel=9)\n",
    "\n",
    "# 3. Evaluar en el mismo X_dev, y_dev (ya que no tenemos un test_final aparte)\n",
    "y_pred_dev = best_pipe.predict(X_dev)\n",
    "mae_dev = mean_absolute_error(y_dev, y_pred_dev)\n",
    "rmse_dev = np.sqrt(mean_squared_error(y_dev, y_pred_dev))\n",
    "r2_dev = r2_score(y_dev, y_pred_dev)\n",
    "mape_dev = mean_absolute_percentage_error(y_dev, y_pred_dev)\n",
    "evs_dev = explained_variance_score(y_dev, y_pred_dev)\n",
    "# print(f\"MAE del mejor modelo ({best_name}) reentrenado en X_dev: {mae_dev:.3f}\")\n",
    "# print(f\"RMSE del mejor modelo ({best_name}) reentrenado en X_dev: {rmse_dev:.3f}\")\n",
    "# print(f\"R2 del mejor modelo ({best_name}) reentrenado en X_dev: {r2_dev:.3f}\")\n",
    "# print(f\"MAPE del mejor modelo ({best_name}) reentrenado en X_dev: {mape_dev:.3f}\")\n",
    "# print(f\"EVS del mejor modelo ({best_name}) reentrenado en X_dev: {evs_dev:.3f}\")\n",
    "\n",
    "# Guardar todas las m√©tricas del modelo final\n",
    "final_metrics = {\n",
    "    'MAE': mae_dev,\n",
    "    'RMSE': rmse_dev,\n",
    "    'R2': r2_dev,\n",
    "    'MAPE': mape_dev,\n",
    "    'EVS': evs_dev,\n",
    "}\n",
    "# print(\"\\nM√©tricas finales del modelo reentrenado:\")\n",
    "print(pd.Series(final_metrics).rename(best_name).to_frame().T.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d237c09",
   "metadata": {},
   "source": [
    "Para inferencia de otros datos con el mismo modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"pers_models/{best_name}.skops\"\n",
    "untrusted = get_untrusted_types(file=model_path) #Esto es una √±apa, porque debo confiar en la funci√≥n lambda de densifier\n",
    "print(\"Untrusted:\", untrusted)\n",
    "model = load(model_path, trusted=untrusted)\n",
    "# pred = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9cc2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Predictivo Mejorado para Precios de Airbnb\n",
    "\n",
    "Este notebook presenta una versión mejorada del modelo predictivo para estimar el precio por noche de propiedades en Airbnb. Incorporamos nuevas métricas de evaluación (EVS y MAPE), técnicas de ingeniería de características y algoritmos de modelado avanzados (XGBoost, LightGBM) para buscar una mayor precisión y una comprensión más profunda de los factores que influyen en el precio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Bibliotecas\n",
    "\n",
    "Importamos las bibliotecas necesarias, incluyendo las nuevas para métricas y modelos adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de bibliotecas estándar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesamiento y Modelado\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Métricas de Evaluación\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "\n",
    "# Función para calcular MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Evitar división por cero\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "# Configuración para visualizaciones\n",
    "plt.style.use(\'seaborn-v0_8-whitegrid\')\n",
    "plt.rcParams[\'figure.figsize\'] = (12, 8)\n",
    "sns.set_palette(\'viridis\')\n",
    "\n",
    "# Para ignorar advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings(\'ignore\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploración Inicial de Datos\n",
    "\n",
    "Cargamos el dataset y realizamos una exploración inicial, similar al notebook anterior, para familiarizarnos con los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv(\'transform_listings.csv\')\n",
    "\n",
    "# Seleccionamos las columnas relevantes\n",
    "columns_to_use = [\'neighbourhood_group_cleansed\', \'latitude\', \'longitude\', \'property_type\', \n",
    "                  \'bathrooms\', \'bedrooms\', \'aire\', \'garaje\', \'calefaccion\', \'ascensor\', \'price\']\n",
    "\n",
    "# Verificamos si todas las columnas existen en el dataset\n",
    "missing_columns = [col for col in columns_to_use if col not in df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Columnas no encontradas en el dataset: {missing_columns}\")\n",
    "else:\n",
    "    print(\"Todas las columnas requeridas están presentes en el dataset.\")\n",
    "\n",
    "# Creamos un nuevo dataframe con las columnas seleccionadas\n",
    "df_selected = df[columns_to_use].copy()\n",
    "\n",
    "# Mostramos las primeras filas e información básica\n",
    "print(\"Primeras 5 filas del dataset seleccionado:\")\n",
    "print(df_selected.head())\n",
    "print(\"\nInformación del dataset seleccionado:\")\n",
    "df_selected.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ingeniería de Características\n",
    "\n",
    "Creamos nuevas características para potencialmente mejorar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Distancia al Centro (Puerta del Sol)\n",
    "# Coordenadas aproximadas de la Puerta del Sol, Madrid\n",
    "sol_lat, sol_lon = 40.416775, -3.703790\n",
    "\n",
    "# Función para calcular la distancia Haversine (distancia en esfera)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radio de la Tierra en km\n",
    "    dLat = np.radians(lat2 - lat1)\n",
    "    dLon = np.radians(lon2 - lon1)\n",
    "    lat1 = np.radians(lat1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    a = np.sin(dLat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dLon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "df_selected[\'dist_sol_km\'] = haversine(df_selected[\'latitude\'], df_selected[\'longitude\'], sol_lat, sol_lon)\n",
    "\n",
    "print(\"Estadísticas descriptivas de la distancia a Sol:\")\n",
    "print(df_selected[\'dist_sol_km\'].describe())\n",
    "\n",
    "# Visualización de la nueva característica\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_selected[\'dist_sol_km\'], kde=True)\n",
    "plt.title(\'Distribución de la Distancia a la Puerta del Sol (km)\')\n",
    "plt.xlabel(\'Distancia (km)\')\n",
    "plt.ylabel(\'Frecuencia\')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Agrupación de Tipos de Propiedad Poco Frecuentes\n",
    "# Identificamos tipos de propiedad con pocas instancias\n",
    "property_counts = df_selected[\'property_type\'].value_counts()\n",
    "threshold = 50 # Umbral para considerar una categoría como poco frecuente\n",
    "rare_properties = property_counts[property_counts < threshold].index.tolist()\n",
    "\n",
    "print(f\"Número de tipos de propiedad antes de agrupar: {len(property_counts)}\")\n",
    "print(f\"Número de tipos de propiedad poco frecuentes (menos de {threshold} instancias): {len(rare_properties)}\")\n",
    "\n",
    "# Agrupamos las categorías poco frecuentes en \'Other\'\n",
    "df_selected[\'property_type_grouped\'] = df_selected[\'property_type\'].apply(lambda x: \'Other\' if x in rare_properties else x)\n",
    "\n",
    "print(f\"\nNúmero de tipos de propiedad después de agrupar: {df_selected[\'property_type_grouped\'].nunique()}\")\n",
    "print(\"\nDistribución de los nuevos tipos de propiedad:\")\n",
    "print(df_selected[\'property_type_grouped\'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento de Datos Mejorado\n",
    "\n",
    "Aplicamos el preprocesamiento, incluyendo el manejo de nulos, la codificación de variables categóricas (usando la nueva variable agrupada) y el escalado de numéricas (incluyendo la nueva variable de distancia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de valores faltantes (igual que antes)\n",
    "print(\"Valores nulos antes de eliminar:\")\n",
    "print(df_selected.isnull().sum())\n",
    "df_clean = df_selected.dropna(subset=[\'bathrooms\', \'bedrooms\', \'price\']) # Aseguramos eliminar nulos en columnas clave\n",
    "print(f\"\nFilas originales: {len(df_selected)}\")\n",
    "print(f\"Filas después de eliminar valores nulos: {len(df_clean)}\")\n",
    "print(f\"Filas eliminadas: {len(df_selected) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado de outliers en el precio (usando un umbral más conservador o transformación log)\n",
    "# Aplicaremos log(price+1) para manejar la asimetría y reducir el impacto de outliers\n",
    "df_clean[\'log_price\'] = np.log1p(df_clean[\'price\'])\n",
    "\n",
    "# Visualización de la distribución del log(precio)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_clean[\'log_price\'], kde=True)\n",
    "plt.title(\'Distribución del Log(Precio+1)\')\n",
    "plt.xlabel(\'Log(Precio+1)\')\n",
    "plt.ylabel(\'Frecuencia\')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos las características (X) y la variable objetivo (y)\n",
    "# Usaremos log_price como objetivo y eliminaremos las columnas originales de precio y tipo de propiedad\n",
    "X = df_clean.drop([\'price\', \'log_price\', \'property_type\'], axis=1)\n",
    "y = df_clean[\'log_price\']\n",
    "\n",
    "# Identificamos las columnas categóricas y numéricas actualizadas\n",
    "categorical_cols = [\'neighbourhood_group_cleansed\', \'property_type_grouped\']\n",
    "numerical_cols = [\'latitude\', \'longitude\', \'bathrooms\', \'bedrooms\', \'aire\', \'garaje\', \'calefaccion\', \'ascensor\', \'dist_sol_km\']\n",
    "\n",
    "# Verificamos que todas las columnas estén incluidas\n",
    "print(f\"Columnas categóricas: {categorical_cols}\")\n",
    "print(f\"Columnas numéricas: {numerical_cols}\")\n",
    "print(f\"Total de columnas en X: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el preprocesador actualizado\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\'imputer\', SimpleImputer(strategy=\'most_frequent\')),\n",
    "    (\'onehot\', OneHotEncoder(handle_unknown=\'ignore\'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\'imputer\', SimpleImputer(strategy=\'median\')),\n",
    "    (\'scaler\', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\'cat\', categorical_transformer, categorical_cols),\n",
    "        (\'num\', numerical_transformer, numerical_cols)\n",
    "    ], remainder=\'passthrough\') # Mantenemos otras columnas si las hubiera\n",
    "\n",
    "# Aplicamos el preprocesador para verificar\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "print(f\"Dimensiones de X_train después del preprocesamiento: {X_train_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelado y Evaluación (con Nuevas Métricas y Modelos)\n",
    "\n",
    "Entrenamos y evaluamos los modelos anteriores y los nuevos (XGBoost, LightGBM), utilizando el conjunto completo de métricas, incluyendo EVS y MAPE. Trabajaremos con la variable objetivo transformada (log_price) y revertiremos la transformación para interpretar las métricas de error (RMSE, MAE, MAPE) en la escala original del precio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de evaluación actualizada\n",
    "def evaluate_model_enhanced(model, X_train, X_test, y_train_log, y_test_log):\n",
    "    # Entrenar el modelo con datos preprocesados\n",
    "    model.fit(X_train, y_train_log)\n",
    "    \n",
    "    # Realizar predicciones en escala logarítmica\n",
    "    y_pred_train_log = model.predict(X_train)\n",
    "    y_pred_test_log = model.predict(X_test)\n",
    "    \n",
    "    # Revertir la transformación logarítmica para evaluación en escala original\n",
    "    y_train_orig = np.expm1(y_train_log)\n",
    "    y_test_orig = np.expm1(y_test_log)\n",
    "    y_pred_train_orig = np.expm1(y_pred_train_log)\n",
    "    y_pred_test_orig = np.expm1(y_pred_test_log)\n",
    "    \n",
    "    # Asegurarse de que las predicciones no sean negativas (puede ocurrir por errores numéricos)\n",
    "    y_pred_train_orig = np.maximum(0, y_pred_train_orig)\n",
    "    y_pred_test_orig = np.maximum(0, y_pred_test_orig)\n",
    "    \n",
    "    # Calcular métricas en escala original\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_orig, y_pred_train_orig))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_test_orig))\n",
    "    train_mae = mean_absolute_error(y_train_orig, y_pred_train_orig)\n",
    "    test_mae = mean_absolute_error(y_test_orig, y_pred_test_orig)\n",
    "    train_mape = mean_absolute_percentage_error(y_train_orig, y_pred_train_orig)\n",
    "    test_mape = mean_absolute_percentage_error(y_test_orig, y_pred_test_orig)\n",
    "    \n",
    "    # Calcular métricas en escala logarítmica (R² y EVS se interpretan mejor en la escala del modelo)\n",
    "    train_r2 = r2_score(y_train_log, y_pred_train_log)\n",
    "    test_r2 = r2_score(y_test_log, y_pred_test_log)\n",
    "    train_evs = explained_variance_score(y_train_log, y_pred_train_log)\n",
    "    test_evs = explained_variance_score(y_test_log, y_pred_test_log)\n",
    "    \n",
    "    return {\n",
    "        \'train_rmse\': train_rmse, \'test_rmse\': test_rmse,\n",
    "        \'train_mae\': train_mae, \'test_mae\': test_mae,\n",
    "        \'train_mape\': train_mape, \'test_mape\': test_mape,\n",
    "        \'train_r2\': train_r2, \'test_r2\': test_r2,\n",
    "        \'train_evs\': train_evs, \'test_evs\': test_evs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los modelos a probar (incluyendo los nuevos)\n",
    "models_enhanced = {\n",
    "    \'Regresión Lineal\': Pipeline(steps=[(\'preprocessor\', preprocessor),\n",
    "                                        (\'regressor\', LinearRegression())]),\n",
    "    \'Ridge\': Pipeline(steps=[(\'preprocessor\', preprocessor),\n",
    "                            (\'regressor\', Ridge(alpha=1.0, random_state=42))]),\n",
    "    \'Lasso\': Pipeline(steps=[(\'preprocessor\', preprocessor),\n",
    "                            (\'regressor\', Lasso(alpha=0.01, random_state=42))]), # Ajustar alpha si es necesario\n",
    "    \'Árbol de Decisión\': Pipeline(steps=[(\'preprocessor\', preprocessor),\n",
    "                                        (\'regressor\', DecisionTreeRegressor(random_state=42))]),\n",
    "    \'Random Forest\': Pipeline(steps=[(\'preprocessor\', preprocessor),\n",
    "                                    (\'regressor\', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))]),\n",
    "    \'Gradient Boosting\': Pipeline(steps=[(\'preprocessor\', preprocessor),\n",
    "                                        (\'regressor\', GradientBoostingRegressor(n_estimators=100, random_state=42))]),\n",
    "    \'XGBoost\': Pipeline(steps=[(\'preprocessor\', preprocessor),\n",
    "                             (\'regressor\', xgb.XGBRegressor(objective=\'reg:squarederror\', n_estimators=100, random_state=42, n_jobs=-1))]),\n",
    "    \'LightGBM\': Pipeline(steps=[(\'preprocessor\', preprocessor),\n",
    "                              (\'regressor\', lgb.LGBMRegressor(objective=\'regression\', n_estimators=100, random_state=42, n_jobs=-1))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos cada modelo y guardamos los resultados\n",
    "results_enhanced = {}\n",
    "\n",
    "for name, model in models_enhanced.items():\n",
    "    print(f\"Evaluando {name}...\")\n",
    "    try:\n",
    "        results_enhanced[name] = evaluate_model_enhanced(model, X_train, X_test, y_train, y_test)\n",
    "        print(f\"  RMSE (Test): {results_enhanced[name][\'test_rmse\']:.2f}\")\n",
    "        print(f\"  MAE (Test): {results_enhanced[name][\'test_mae\']:.2f}\")\n",
    "        print(f\"  MAPE (Test): {results_enhanced[name][\'test_mape\']:.2f}%\")\n",
    "        print(f\"  R² (Test): {results_enhanced[name][\'test_r2\']:.4f}\")\n",
    "        print(f\"  EVS (Test): {results_enhanced[name][\'test_evs\']:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluando {name}: {e}\")\n",
    "        results_enhanced[name] = {k: np.nan for k in [\'train_rmse\', \'test_rmse\', \'train_mae\', \'test_mae\', \'train_mape\', \'test_mape\', \'train_r2\', \'test_r2\', \'train_evs\', \'test_evs\']}\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con los resultados para facilitar la comparación\n",
    "results_list = []\n",
    "for name, metrics in results_enhanced.items():\n",
    "    metrics[\'Modelo\'] = name\n",
    "    results_list.append(metrics)\n",
    "\n",
    "results_df_enhanced = pd.DataFrame(results_list)\n",
    "\n",
    "# Reordenamos las columnas para mejor visualización\n",
    "cols_order = [\'Modelo\', \'test_rmse\', \'test_mae\', \'test_mape\', \'test_r2\', \'test_evs\', \n",
    "              \'train_rmse\', \'train_mae\', \'train_mape\', \'train_r2\', \'train_evs\']\n",
    "results_df_enhanced = results_df_enhanced[cols_order]\n",
    "\n",
    "# Ordenamos por RMSE en el conjunto de prueba (menor es mejor)\n",
    "results_df_enhanced = results_df_enhanced.sort_values(\'test_rmse\')\n",
    "\n",
    "print(\"Tabla comparativa de modelos:\")\n",
    "results_df_enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explicación de Métricas y Selección del Modelo\n",
    "\n",
    "A continuación, explicamos el significado de cada métrica utilizada y cómo nos ayudan a seleccionar el modelo más adecuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de Métricas\n",
    "\n",
    "1.  **RMSE (Root Mean Squared Error - Error Cuadrático Medio Raíz)**:\n",
    "    -   *Qué mide*: La desviación estándar de los residuos (errores de predicción). Penaliza más los errores grandes.\n",
    "    -   *Unidad*: La misma que la variable objetivo (en este caso, euros, ya que evaluamos en la escala original).\n",
    "    -   *Interpretación*: Un valor más bajo indica un mejor ajuste del modelo. Representa el error típico de predicción.\n",
    "\n",
    "2.  **MAE (Mean Absolute Error - Error Absoluto Medio)**:\n",
    "    -   *Qué mide*: El promedio de los errores absolutos (|real - predicción|).\n",
    "    -   *Unidad*: La misma que la variable objetivo (euros).\n",
    "    -   *Interpretación*: Un valor más bajo indica un mejor ajuste. Es menos sensible a outliers que el RMSE y representa el error promedio absoluto.\n",
    "\n",
    "3.  **MAPE (Mean Absolute Percentage Error - Error Porcentual Absoluto Medio)**:\n",
    "    -   *Qué mide*: El error absoluto promedio como un porcentaje del valor real.\n",
    "    -   *Unidad*: Porcentaje (%).\n",
    "    -   *Interpretación*: Un valor más bajo indica un mejor ajuste. Es útil para comparar el rendimiento entre diferentes escalas o datasets. Un MAPE del 10% significa que, en promedio, la predicción difiere del valor real en un 10%. *Precaución*: Puede ser problemático si los valores reales son cercanos a cero.\n",
    "\n",
    "4.  **R² (R-squared - Coeficiente de Determinación)**:\n",
    "    -   *Qué mide*: La proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes. Se calcula sobre la escala logarítmica en nuestro caso.\n",
    "    -   *Rango*: Teóricamente de -∞ a 1. Un valor cercano a 1 indica que el modelo explica una gran parte de la variabilidad. Un valor de 0 indica que el modelo no es mejor que predecir simplemente la media. Valores negativos indican un modelo muy malo.\n",
    "    -   *Interpretación*: Un valor más alto generalmente indica un mejor ajuste (en la escala logarítmica).\n",
    "\n",
    "5.  **EVS (Explained Variance Score - Puntuación de Varianza Explicada)**:\n",
    "    -   *Qué mide*: Similar al R², mide la proporción de la varianza de la variable objetivo que el modelo logra explicar. Se calcula sobre la escala logarítmica.\n",
    "    -   *Rango*: De -∞ a 1. Un valor de 1 indica una predicción perfecta.\n",
    "    -   *Interpretación*: Un valor más alto indica un mejor ajuste. Es útil porque compara la varianza del error de predicción con la varianza de los valores reales.\n",
    "\n",
    "### Criterios de Selección\n",
    "\n",
    "La elección del \"mejor\" modelo depende de los objetivos:\n",
    "\n",
    "-   **Si la prioridad es la precisión general (minimizar el error típico):** Nos fijamos principalmente en el **RMSE** y **MAE** (valores más bajos son mejores). El **MAPE** da una idea del error relativo.\n",
    "-   **Si la prioridad es explicar la variabilidad de los precios:** Nos fijamos en **R²** y **EVS** (valores más altos son mejores, cercanos a 1).\n",
    "-   **Si la prioridad es un modelo robusto y generalizable:** Comparamos las métricas entre los conjuntos de *entrenamiento* y *prueba*. Una diferencia grande indica sobreajuste (el modelo memoriza los datos de entrenamiento pero no generaliza bien a datos nuevos). Buscamos modelos donde las métricas de prueba sean cercanas a las de entrenamiento.\n",
    "-   **Si la prioridad es la interpretabilidad:** Modelos como Regresión Lineal, Ridge, Lasso o Árboles de Decisión (con profundidad limitada) son más fáciles de interpretar que los ensembles complejos como Random Forest, Gradient Boosting, XGBoost o LightGBM.\n",
    "-   **Consideraciones prácticas:** El tiempo de entrenamiento y predicción también puede ser un factor, especialmente con grandes datasets.\n",
    "\n",
    "En nuestro caso, buscamos un buen equilibrio. Observando la tabla `results_df_enhanced`, podemos identificar los modelos con los menores errores (RMSE, MAE, MAPE) y los mayores R²/EVS en el conjunto de prueba, sin una diferencia excesiva respecto al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización comparativa de métricas clave (Test set)\n",
    "metrics_to_plot = [\'test_rmse\', \'test_mae\', \'test_mape\', \'test_r2\', \'test_evs\']\n",
    "n_metrics = len(metrics_to_plot)\n",
    "n_cols = 3\n",
    "n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    # Ordenar por la métrica actual para la visualización\n",
    "    sort_ascending = not (metric in [\'test_r2\', \'test_evs\']) # RMSE, MAE, MAPE son mejores cuanto más bajos\n",
    "    df_sorted = results_df_enhanced.sort_values(metric, ascending=sort_ascending)\n",
    "    \n",
    "    sns.barplot(x=\'Modelo\', y=metric, data=df_sorted, ax=axes[i], palette=\'viridis\')\n",
    "    axes[i].set_title(f\'{metric.upper()} por Modelo (Test Set)\')\n",
    "    axes[i].tick_params(axis=\'x\', rotation=45)\n",
    "    axes[i].set_xlabel(\'Modelo\')\n",
    "    axes[i].set_ylabel(metric.split(\'_\')[-1].upper())\n",
    "\n",
    "# Ocultar ejes sobrantes\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimización del Mejor Modelo (Opcional)\n",
    "\n",
    "Basándonos en las métricas, seleccionamos el modelo con mejor rendimiento general (por ejemplo, LightGBM o XGBoost suelen destacar) y realizamos una búsqueda de hiperparámetros para intentar mejorarlo aún más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el mejor modelo (ej: basado en menor RMSE en test)\n",
    "best_model_name = results_df_enhanced.iloc[0][\'Modelo\']\n",
    "print(f\"El mejor modelo inicial es: {best_model_name}\")\n",
    "\n",
    "# Definir el pipeline y la rejilla de parámetros para el mejor modelo\n",
    "# (Ejemplo para LightGBM, ajustar según el modelo seleccionado)\n",
    "if best_model_name == \'LightGBM\':\n",
    "    param_grid = {\n",
    "        \'regressor__n_estimators\': [100, 200, 500],\n",
    "        \'regressor__learning_rate\': [0.01, 0.05, 0.1],\n",
    "        \'regressor__num_leaves\': [31, 50, 70],\n",
    "        \'regressor__max_depth\': [-1, 10, 20],\n",
    "        \'regressor__colsample_bytree\': [0.7, 0.9, 1.0],\n",
    "        \'regressor__subsample\': [0.7, 0.9, 1.0]\n",
    "    }\n",
    "    base_model = lgb.LGBMRegressor(objective=\'regression\', random_state=42, n_jobs=-1)\n",
    "elif best_model_name == \'XGBoost\':\n",
    "     param_grid = {\n",
    "        \'regressor__n_estimators\': [100, 200, 500],\n",
    "        \'regressor__learning_rate\': [0.01, 0.05, 0.1],\n",
    "        \'regressor__max_depth\': [3, 5, 7],\n",
    "        \'regressor__colsample_bytree\': [0.7, 0.9, 1.0],\n",
    "        \'regressor__subsample\': [0.7, 0.9, 1.0]\n",
    "    }\n",
    "     base_model = xgb.XGBRegressor(objective=\'reg:squarederror\', random_state=42, n_jobs=-1)\n",
    "# Añadir elif para otros modelos si es necesario...\n",
    "else:\n",
    "    print(\"Optimización no configurada para este modelo o no necesaria.\")\n",
    "    param_grid = None\n",
    "\n",
    "# Realizar GridSearchCV si hay parámetros definidos\n",
    "if param_grid:\n",
    "    print(f\"\nRealizando búsqueda de hiperparámetros para {best_model_name}...\")\n",
    "    pipeline_to_tune = Pipeline(steps=[(\'preprocessor\', preprocessor), (\'regressor\', base_model)])\n",
    "    \n",
    "    # Usamos neg_root_mean_squared_error para optimizar RMSE directamente\n",
    "    # Nota: Trabajamos sobre y_train (log_price)\n",
    "    grid_search = GridSearchCV(pipeline_to_tune, param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=42), \n",
    "                             scoring=\'neg_root_mean_squared_error\', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Mejores parámetros encontrados:\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    # Evaluar el modelo optimizado\n",
    "    optimized_model = grid_search.best_estimator_\n",
    "    print(\"\nEvaluando modelo optimizado:\")\n",
    "    optimized_results = evaluate_model_enhanced(optimized_model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    print(f\"  RMSE (Test): {optimized_results[\'test_rmse\']:.2f}\")\n",
    "    print(f\"  MAE (Test): {optimized_results[\'test_mae\']:.2f}\")\n",
    "    print(f\"  MAPE (Test): {optimized_results[\'test_mape\']:.2f}%\")\n",
    "    print(f\"  R² (Test): {optimized_results[\'test_r2\']:.4f}\")\n",
    "    print(f\"  EVS (Test): {optimized_results[\'test_evs\']:.4f}\")\n",
    "else:\n",
    "    optimized_model = models_enhanced[best_model_name] # Usar el modelo sin optimizar si no se hizo grid search\n",
    "    optimized_results = results_enhanced[best_model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análisis de Importancia de Características (Modelo Final)\n",
    "\n",
    "Analizamos qué características son más influyentes en las predicciones del modelo final optimizado (si es un modelo basado en árboles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentar obtener la importancia de características del modelo final\n",
    "try:\n",
    "    # Acceder al estimador dentro del pipeline\n",
    "    final_regressor = optimized_model.named_steps[\'regressor\']\n",
    "    \n",
    "    if hasattr(final_regressor, \'feature_importances_\'):\n",
    "        # Obtener nombres de características del preprocesador\n",
    "        preprocessor_fitted = optimized_model.named_steps[\'preprocessor\']\n",
    "        cat_features_names = preprocessor_fitted.named_transformers_[\'cat\'].named_steps[\'onehot\'].get_feature_names_out(categorical_cols)\n",
    "        num_features_names = numerical_cols\n",
    "        \n",
    "        # Combinar nombres de características\n",
    "        if hasattr(preprocessor_fitted, \'get_feature_names_out\'):\n",
    "             # Para versiones más nuevas de scikit-learn\n",
    "             feature_names = preprocessor_fitted.get_feature_names_out()\n",
    "        else:\n",
    "             # Fallback para versiones anteriores (puede requerir ajuste)\n",
    "             feature_names = list(cat_features_names) + list(num_features_names)\n",
    "\n",
    "        importances = final_regressor.feature_importances_\n",
    "        \n",
    "        # Crear DataFrame de importancia\n",
    "        importance_df = pd.DataFrame({\'Feature\': feature_names, \'Importance\': importances})\n",
    "        importance_df = importance_df.sort_values(\'Importance\', ascending=False)\n",
    "        \n",
    "        # Visualizar las top 20 características\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.barplot(x=\'Importance\', y=\'Feature\', data=importance_df.head(20), palette=\'viridis\')\n",
    "        plt.title(f\'Top 20 Características Más Importantes ({best_model_name} Optimizado)\')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\nTop 20 Características:\")\n",
    "        print(importance_df.head(20))\n",
    "        \n",
    "    else:\n",
    "        print(f\"El modelo {best_model_name} no tiene el atributo \'feature_importances_\'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"No se pudo obtener la importancia de características: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualización de Predicciones (Modelo Final)\n",
    "\n",
    "Visualizamos las predicciones del modelo final en comparación con los valores reales, tanto en escala logarítmica como original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones con el modelo final optimizado\n",
    "y_pred_train_log_final = optimized_model.predict(X_train)\n",
    "y_pred_test_log_final = optimized_model.predict(X_test)\n",
    "\n",
    "# Revertir a escala original\n",
    "y_train_orig = np.expm1(y_train)\n",
    "y_test_orig = np.expm1(y_test)\n",
    "y_pred_train_orig_final = np.expm1(y_pred_train_log_final)\n",
    "y_pred_test_orig_final = np.expm1(y_pred_test_log_final)\n",
    "\n",
    "# Asegurar no negativos\n",
    "y_pred_train_orig_final = np.maximum(0, y_pred_train_orig_final)\n",
    "y_pred_test_orig_final = np.maximum(0, y_pred_test_orig_final)\n",
    "\n",
    "# Crear DataFrame para visualización (Test set)\n",
    "pred_df_final = pd.DataFrame({\n",
    "    \'Real_Log\': y_test,\n",
    "    \'Predicho_Log\': y_pred_test_log_final,\n",
    "    \'Real_Original\': y_test_orig,\n",
    "    \'Predicho_Original\': y_pred_test_orig_final\n",
    "})\n",
    "pred_df_final[\'Residuo_Log\'] = pred_df_final[\'Real_Log\'] - pred_df_final[\'Predicho_Log\']\n",
    "pred_df_final[\'Residuo_Original\'] = pred_df_final[\'Real_Original\'] - pred_df_final[\'Predicho_Original\']\n",
    "\n",
    "# Visualización: Real vs Predicho (Escala Original)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pred_df_final[\'Real_Original\'], pred_df_final[\'Predicho_Original\'], alpha=0.3)\n",
    "max_val = max(pred_df_final[\'Real_Original\'].max(), pred_df_final[\'Predicho_Original\'].max())\n",
    "min_val = min(pred_df_final[\'Real_Original\'].min(), pred_df_final[\'Predicho_Original\'].min())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], \'r--\', lw=2)\n",
    "plt.xlabel(\'Precio Real (€)\')\n",
    "plt.ylabel(\'Precio Predicho (€)\')\n",
    "plt.title(f\'Comparación Real vs. Predicho ({best_model_name} Optimizado - Escala Original)\')\n",
    "plt.xlim(min_val, max_val) # Ajustar límites si es necesario\n",
    "plt.ylim(min_val, max_val)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización: Distribución de Residuos (Escala Original)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(pred_df_final[\'Residuo_Original\'], kde=True)\n",
    "plt.title(\'Distribución de Residuos (Escala Original)\')\n",
    "plt.xlabel(\'Error de Predicción (€)\')\n",
    "plt.ylabel(\'Frecuencia\')\n",
    "\n",
    "# Visualización: Residuos vs Predicciones (Escala Original)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(pred_df_final[\'Predicho_Original\'], pred_df_final[\'Residuo_Original\'], alpha=0.3)\n",
    "plt.axhline(y=0, color=\'r\', linestyle=\'--\')\n",
    "plt.xlabel(\'Precio Predicho (€)\')\n",
    "plt.ylabel(\'Residuo (€)\')\n",
    "plt.title(\'Residuos vs. Predicciones (Escala Original)\')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusiones Mejoradas\n",
    "\n",
    "Resumimos los hallazgos de este análisis mejorado, destacando el rendimiento del modelo final y las características más influyentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de Resultados\n",
    "\n",
    "En esta versión mejorada, hemos aplicado ingeniería de características (distancia al centro, agrupación de tipos de propiedad), transformado la variable objetivo (log(precio+1)) para manejar la asimetría, introducido nuevos algoritmos (XGBoost, LightGBM) y evaluado los modelos con métricas adicionales (EVS, MAPE).\n",
    "\n",
    "Los modelos basados en ensambles, particularmente [MEJOR MODELO INICIAL] y [SEGUNDO MEJOR MODELO], mostraron el mejor rendimiento general en el conjunto de prueba. Después de la optimización de hiperparámetros para [MEJOR MODELO INICIAL], logramos las siguientes métricas en el conjunto de prueba:\n",
    "-   **RMSE**: [VALOR RMSE OPTIMIZADO] €\n",
    "-   **MAE**: [VALOR MAE OPTIMIZADO] €\n",
    "-   **MAPE**: [VALOR MAPE OPTIMIZADO] %\n",
    "-   **R² (log)**: [VALOR R2 OPTIMIZADO]\n",
    "-   **EVS (log)**: [VALOR EVS OPTIMIZADO]\n",
    "\n",
    "Esto representa una mejora respecto al análisis inicial, indicando que las nuevas características y algoritmos contribuyeron a una mejor predicción.\n",
    "\n",
    "### Características Más Importantes\n",
    "\n",
    "El análisis de importancia de características del modelo [MEJOR MODELO OPTIMIZADO] reveló que los factores más influyentes en el precio (logarítmico) son:\n",
    "1.  [CARACTERÍSTICA 1]\n",
    "2.  [CARACTERÍSTICA 2]\n",
    "3.  [CARACTERÍSTICA 3]\n",
    "4.  [CARACTERÍSTICA 4]\n",
    "5.  [CARACTERÍSTICA 5]\n",
    "\n",
    "La inclusión de la distancia al centro ([dist_sol_km]) y la agrupación de tipos de propiedad también parecen haber aportado información relevante.\n",
    "\n",
    "### Próximos Pasos y Limitaciones\n",
    "\n",
    "-   **Explorar más características:** Se podrían añadir datos externos (ej. índices económicos, eventos) o extraer más información de las descripciones o amenities.\n",
    "-   **Modelos más complejos:** Probar redes neuronales o ensambles más sofisticados (stacking/blending).\n",
    "-   **Análisis de errores:** Investigar en qué tipos de propiedades o rangos de precios el modelo comete mayores errores.\n",
    "-   **Interpretabilidad avanzada:** Usar técnicas como SHAP para entender mejor las predicciones individuales.\n",
    "\n",
    "Las limitaciones incluyen la dependencia de la calidad de los datos de entrada y la posible omisión de factores no capturados en el dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
